---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<div class="wordwrap">You can also find my articles on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>

<h2><span>2024</span></h2>
  <div class="flex-row" onmouseout="par2net_stop()" onmouseover="par2net_start()">
    <div class="image-container">
      <img src="../images/500x300.png" width="160" alt="Image">
    </div>
    <div class="text-container">
      <papertitle>Color4E: Event demosaicing for full-color event guided image deblurring</papertitle>
      <br>
      Yi Ma<sup>#</sup>,<strong>Peiqi Duan<sup>#</sup></strong>, Yuchen Hong, Chu Zhou, Yu Zhang, Jimmy Ren, and Boxin Shi<sup>*</sup>
      <br>
      <em>ACM MM</em>, 2024
      <br>
    </div>
  </div>

  <div class="flex-row" onmouseout="par2net_stop()" onmouseover="par2net_start()">
    <div class="image-container">
      <img src="../images/500x300.png" width="160" alt="Image">
    </div>
    <div class="text-container">
      <papertitle>EvDiG: Event-guided direct and global components separation</papertitle>
      <br>
      Xinyu Zhou, <strong>Peiqi Duan</strong>, Boyu Li, Chu Zhou, Chao Xu, and Boxin Shi<sup>*</sup>
      <br>
      <em>CVPR</em>, 2024
      <br>
      <a href="https://assets.ctfassets.net/yreyglvi5sud/4rrKmGuR98bvBBmLlZK7i3/7c2a00d49adde30a4caba7cdec852f24/Zhou_CVPR24.pdf">[paper]</a> 
      <a href="https://www.youtube.com/watch?v=y0bMZnUJt14">[video]</a>
    </div>
  </div>

<h2><span>2023</span></h2>
  <div class="flex-row" onmouseout="par2net_stop()" onmouseover="par2net_start()">
    <div class="image-container">
      <img src="../images/500x300.png" width="160" alt="Image">
    </div>
    <div class="text-container">
      <papertitle>Hybrid high dynamic range imaging fusing neuromorphic and conventional images</papertitle>
      <br>
      Jin Han, Yixin Yang, <strong>Peiqi Duan</strong>, Chu Zhou, Lei Ma, Chao Xu, Tiejun Huang, Imari Sato, and Boxin Shi<sup>*</sup>
      <br>
      <em>TPAMI</em>, 2023
      <br>
      <a href="https://downloads.ctfassets.net/yreyglvi5sud/7yA8sqjDJilRmL5iseiRpB/734af0b70b6b8966d79ff4dd6d8cf73a/Han_TPAMI22.pdf">[paper]</a> 
      <a href="https://github.com/hjynwa/NeurImg-HDR">[website]</a>
    </div>
  </div>

  <div class="flex-row" onmouseout="par2net_stop()" onmouseover="par2net_start()">
    <div class="image-container">
      <img src="../images/500x300.png" width="160" alt="Image">
    </div>
    <div class="text-container">
      <papertitle>NeuroZoom: Denoising and super resolving neuromorphic events and spikes</papertitle>
      <br>
      <strong>Peiqi Duan</strong>, Yi Ma, Xinyu Zhou, Xinyu Shi, Zihao W. Wang, Tiejun Huang, and Boxin Shi<sup>*</sup>
      <br>
      <em>TPAMI</em>, 2023
      <br>
      <a href="https://downloads.ctfassets.net/yreyglvi5sud/CfT1NA9r1HNehoQqZyf5t/0f0e305cfd5b73471226f5ef1dfa52fe/Duan_TPAMI23_comp.pdf">[paper]</a> 
      <a href="https://github.com/hjynwa/NeurImg-HDR">[website]</a>
    </div>
  </div>

  <div class="flex-row" onmouseout="par2net_stop()" onmouseover="par2net_start()">
    <div class="image-container">
      <img src="../images/500x300.png" width="160" alt="Image">
    </div>
    <div class="text-container">
      <papertitle>Coherent event guided low-light video enhancement</papertitle>
      <br>
      Jinxiu Liang, Yixin Yang, Boyu Li, <strong>Peiqi Duan</strong>, Yong Xu, and Boxin Shi<sup>*</sup>
      <br>
      <em>ICCV</em>, 2023
      <br>
      <a href="https://assets.ctfassets.net/yreyglvi5sud/4jmy8h8OR0kmr3Oj1YaOIf/94751ea976fee4b06d9127095ac0249c/Liang_ICCV23a.pdf">[paper]</a> 
      <a href="https://sherrycattt.github.io/EvLowLight/">[website]</a>
    </div>
  </div>

<h2><span>2022</span></h2>
  <div class="flex-row" onmouseout="par2net_stop()" onmouseover="par2net_start()">
    <div class="image-container">
      <img src="../images/500x300.png" width="160" alt="Image">
    </div>
    <div class="text-container">
      <papertitle>Data association between event streams and intensity frames under diverse baselines</papertitle>
      <br>
      Dehao Zhang, Qiankun Ding, <strong>Peiqi Duan</strong>, Chu Zhou, and Boxin Shi<sup>*</sup>
      <br>
      <em>ECCV</em>, 2022
      <br>
      <a href="https://assets.ctfassets.net/yreyglvi5sud/77lslHrshWxDUxmUla9out/b1772a73762d82a0a039fa96d506bbc3/Zhang_ECCV22e.pdf">[paper]</a> 
    </div>
  </div>

   <div class="flex-row" onmouseout="par2net_stop()" onmouseover="par2net_start()">
    <div class="image-container">
      <img src="../images/500x300.png" width="160" alt="Image">
    </div>
    <div class="text-container">
      <papertitle>EvUnroll: Neuromorphic events based rolling shutter image correction</papertitle>
      <br>
     Xinyu Zhou<sup>#</sup>,<strong>Peiqi Duan<sup>#</sup></strong>, Yi Ma, and Boxin Shi<sup>*</sup>
      <br>
      <em>CVPR</em>, 2022
      <br>
      <a href="https://assets.ctfassets.net/yreyglvi5sud/1VoRnvDiIhvSnL0yc7TpAh/4e69c5da94f6d61e3f7172a10edf92b2/Zhou_CVPR22a.pdf">[paper]</a> 
      <a href="https://github.com/zxyemo/EvUnroll">[website]</a>
    </div>
  </div>


<style>
    /* Flexbox 容器 */
    .flex-row {
      display: flex;
      align-items: center; /* 垂直居中 */
      padding: 20px;
      /* 可选：添加背景颜色或其他样式 */
      /* background-color: #f9f9f9; */
    }

    /* 图片容器 */
    .image-container {
      flex: 0 0 160px; /* 固定宽度 */
      margin-right: 20px; /* 图片与文字之间的间距 */
    }

    /* 确保图片不带边框且适应容器 */
    .image-container img {
      display: block;
      width: 160px;
      height: auto;
    }

    /* 文字容器 */
    .text-container {
      flex: 1; /* 占据剩余空间 */
    }

    /* 自定义 papertitle 样式 */
    papertitle {
      font-size: 1em;
      font-weight: bold;
    }

    /* 移除默认的表格样式（如果仍在使用表格） */
    table, td {
      border: none;
      padding: 0;
    }
  </style>
